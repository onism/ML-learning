# 判别模型和生成模型

判别模型：通过求解条件概率分布$P(y|x)$或直接计算$y$的值来预测$y$。常见的判别模型有：线性回归，逻辑回归，SVM，传统神经网络，线性判别分析 LDA，CRF等
生成模型：通过观测值和标注数据计算联合概率分布$P(x,y)$来达到判定估算$y$的目的，常见的有HMM，bayesian networks, naive bayes, latent dirichlet allocation 等。

# 中文分词方法
中文分词的基本方法可以分为
1. 基于语法规则
2. 基于词典：最大匹配法，最短路径，最大概率等
3. 基于统计：HMM，CRF，MAXENT（最大熵模型），MEMM（最大熵隐马尔科夫模型）。其中HMM是对转移概率和表现概率等直接建模，统计共现概率，而MEMM是对转移概率和表现概率建立联合概率，统计时统计的是条件概率，CRF是在给定需要标记的观测序列等条件下，计算整个标记序列的联合概率分布。 MEMM容易陷入局部最优。CRF可以容纳任意上下文信息，特征设计灵活，但是需要训练等参数更多，存在训练代价大，复杂度高的缺点。

# 维特比算法

Viterbi算法是一种动态规划算法，假设给定HMM观测值空间为$O=\{o_1, ..., o_N \}$,状态空间为$S=\{s_1,...,s_K \}$，观测值序列为$Y=\{y_1,...,y_T \}$, 初始状态$i$的概率为$\pi_i$,从状态$i$到状态$j$的条件转移概率为$a_{ij}$。则产生观测结果最有可能对状态序列$x_1,...,x_T$由递推关系给出

$V_{1,k} = P(y_1|k) \cdot \pi_k$

$V_{t,k} = P(y_t|k) \cdot \max_{x \in S}(a_{x,k}\cdot V_{t-1,x})$.

每个时刻有$K$个可能状态，每个状态需要遍历$K$个数才能得到，有$T$个时间，最终对时间复杂度为$O(TK^2)$.时间复杂度与观察值序列和状态空间有关，与观察值空间无关。

EM：只有观测序列，无状态序列时用来学习模型参数
维特比：用动态规划来解决HMM预测问题，无法用来参数估计
前向后向：用来算概率
极大似然：观测序列和相应状态序列都存在时的监督学习算法，用来参数估计

#  过拟合

机器学习中发生过拟合的主要原因有：
1. 使用过于负责的模型
2. 数据噪声大
3. 训练数据少

降低过拟合的方法有
1. 简化模型假设，或者使用惩罚项限制模型大复杂度
2. 进行数据清洗，减少噪声
3. 收集更多的训练数据

# 线性回归

再经典大线性回归大假定下，最小二乘估计量是具有最小方差的无偏估计量，

# Fisher线性判别函数
Fisher线性判别函数 是将多维空间中的特征矢量投影到一条直线上，也就是将维度压缩到一维。寻找这条最优直线的准则：两类样本在一维空间的投影尽可能密集，类间尽可能分开，也就是投影后两类样本均值之差尽可能大，类内方差尽可能小。

# 深度学习中的归一化问题
1. 避免数值问题
2. 使网络快速大收敛
3. 样本数据的评价标准不一样，需要对其量纲化，统一评价标准
4. 防止净输入绝对值过大引起的神经元输出饱和现象
5. 保证输出数据中值小的不被吞食

# 什么是卷积？

对输入数据（例如图像）和滤波矩阵做内积（逐个元素相乘求和）的操作就是所谓对卷积。